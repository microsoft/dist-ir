{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "helpful-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict, OrderedDict\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import dist_ir\n",
    "from dist_ir.importer import import_from_onnx, parse_tensor_from_file\n",
    "from dist_ir.ir import FunctionMaker, cpprint, pformat, Device, Topology, Value\n",
    "from dist_ir.executor import infer_types, SequentialExecutor, Simulator\n",
    "from dist_ir.executor.cost_model import CostModel\n",
    "from dist_ir.ir.type import Bool, Float, Int64, Tensor\n",
    "from dist_ir.transforms import (\n",
    "    mlp_dhp_transform,\n",
    "    filter_transform,\n",
    "    PipeDreamScheduler,\n",
    ")\n",
    "from examples.mlp import mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-suggestion",
   "metadata": {},
   "source": [
    "## Isolated parallelism simulation results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-rover",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "possible-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "DGX_BANDWIDTH_GBPS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-wallet",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_devices_to_topology(topology, num_devices):\n",
    "    for i in range(num_devices):\n",
    "        topology.add_device(\"gpu\")\n",
    "    devices = topology.devices\n",
    "    for i in range(0, len(devices)):\n",
    "        for j in range(i+1, len(devices)):\n",
    "            topology.set_bandwidth(devices[i], devices[j], DGX_BANDWIDTH_GBPS)\n",
    "    return topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-vacuum",
   "metadata": {},
   "source": [
    "### Data parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unknown-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_num_devices = [2, 4, 8, 16, 32]\n",
    "all_batch_sizes = [512, 1024, 2048, 4096]\n",
    "input_dim = 4096\n",
    "hidden_dim = input_dim\n",
    "output_dim = hidden_dim\n",
    "num_hidden_layers = 64\n",
    "dp_results = defaultdict(list)\n",
    "for batch_size in all_batch_sizes:\n",
    "    topology = Topology()\n",
    "    d0 = topology.add_device(\"gpu\")\n",
    "    function = mlp(batch_size, input_dim, hidden_dim, output_dim, num_hidden_layers, d0)\n",
    "    function = infer_types(function, function.inputs)\n",
    "    simulator = Simulator(CostModel(topology))\n",
    "    simulation = simulator.interpret(\n",
    "        function,\n",
    "        (v.type for v in function.inputs),\n",
    "    )\n",
    "    sequential_running_time = max(\n",
    "        [simulation.timestamps[d] for d in simulation.timestamps]\n",
    "    )\n",
    "    for i, num_devices in enumerate(all_num_devices):\n",
    "        if i == 0:\n",
    "            add_devices_to_topology(topology, num_devices)\n",
    "        else:\n",
    "            add_devices_to_topology(\n",
    "                topology, all_num_devices[i] - all_num_devices[i - 1]\n",
    "            )\n",
    "        assert len(topology.devices) == all_num_devices[i] + 1\n",
    "        simulator = Simulator(CostModel(topology))\n",
    "        transformed_function = mlp_dhp_transform(\n",
    "            function,\n",
    "            num_devices,\n",
    "            1,\n",
    "            1,\n",
    "            topology.devices,\n",
    "            1,\n",
    "        )\n",
    "        transformed_function = infer_types(\n",
    "            transformed_function, transformed_function.inputs\n",
    "        )\n",
    "        transformed_function, typed_input_values = filter_transform(\n",
    "            transformed_function, filter_set=set([\"MPIBroadcast\", \"Send\"])\n",
    "        )\n",
    "        transformed_function = infer_types(transformed_function, typed_input_values)\n",
    "        simulation = simulator.interpret(\n",
    "            transformed_function,\n",
    "            (v.type for v in transformed_function.inputs),\n",
    "        )\n",
    "        distributed_running_time = max(\n",
    "            [simulation.timestamps[d] for d in simulation.timestamps]\n",
    "        )\n",
    "        speedup = sequential_running_time / distributed_running_time\n",
    "        dp_results[batch_size].append(speedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-mining",
   "metadata": {},
   "source": [
    "### Pipeline parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_num_devices = [2, 4, 8, 16, 32]\n",
    "all_num_microbatches = [4, 8, 16, 32]\n",
    "input_dim = 4096\n",
    "hidden_dim = input_dim\n",
    "output_dim = hidden_dim\n",
    "num_hidden_layers = 64\n",
    "batch_size = 4096\n",
    "pp_results = defaultdict(list)\n",
    "topology = Topology()\n",
    "d0 = topology.add_device(\"gpu\")\n",
    "function = mlp(batch_size, input_dim, hidden_dim, output_dim, num_hidden_layers, d0)\n",
    "function = infer_types(function, function.inputs)\n",
    "simulator = Simulator(CostModel(topology))\n",
    "simulation = simulator.interpret(\n",
    "    function,\n",
    "    (v.type for v in function.inputs),\n",
    ")\n",
    "sequential_running_time = max([simulation.timestamps[d] for d in simulation.timestamps])\n",
    "for i, num_microbatches in enumerate(all_num_microbatches):\n",
    "    topology = Topology()\n",
    "    d0 = topology.add_device(\"gpu\")\n",
    "    for j, num_devices in enumerate(all_num_devices):\n",
    "        if j == 0:\n",
    "            add_devices_to_topology(topology, num_devices)\n",
    "        else:\n",
    "            add_devices_to_topology(\n",
    "                topology, all_num_devices[j] - all_num_devices[j - 1]\n",
    "            )\n",
    "        assert len(topology.devices) == all_num_devices[j] + 1\n",
    "        simulator = Simulator(CostModel(topology))\n",
    "        transformed_function = mlp_dhp_transform(\n",
    "            function,\n",
    "            1,\n",
    "            1,\n",
    "            num_devices,\n",
    "            topology.devices,\n",
    "            num_microbatches,\n",
    "        )\n",
    "        transformed_function = infer_types(\n",
    "            transformed_function, transformed_function.inputs\n",
    "        )\n",
    "        transformed_function, typed_input_values = filter_transform(\n",
    "            transformed_function,\n",
    "            filter_set=set([\"Send\"]),\n",
    "            exception_set=set(transformed_function.inputs[:2]),\n",
    "        )\n",
    "        transformed_function = infer_types(transformed_function, typed_input_values)\n",
    "        simulation = simulator.interpret(\n",
    "            transformed_function,\n",
    "            (v.type for v in transformed_function.inputs),\n",
    "        )\n",
    "        distributed_running_time = max(\n",
    "            [simulation.timestamps[d] for d in simulation.timestamps]\n",
    "        )\n",
    "        speedup = sequential_running_time / distributed_running_time\n",
    "        pp_results[num_microbatches].append(speedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-homeless",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 12\n",
    "fig, axes = plt.subplots(2, 1, figsize=(5, 4), sharex=True, sharey=True)\n",
    "markers = [\"o\", \"D\", \"v\", \"s\", \"<\", \"x\"]\n",
    "styles = [\"-\", \"--\", \"-.\", \":\", (0, (3, 1, 1, 1, 1, 1))]\n",
    "c = np.arange(1, len(pp_results) + 3)\n",
    "norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "dp_cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Blues)\n",
    "dp_cmap.set_array([])\n",
    "pp_cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Greens)\n",
    "pp_cmap.set_array([])\n",
    "dp_lines = []\n",
    "dp_labels = []\n",
    "for i, batch_size in enumerate(dp_results):\n",
    "    dp_labels.append(f\"Batch size {batch_size}\")\n",
    "    l = axes[0].plot(\n",
    "        all_num_devices,\n",
    "        dp_results[batch_size],\n",
    "        marker=markers[i],\n",
    "        linestyle=styles[i],\n",
    "        label=dp_labels[-1],\n",
    "        c=dp_cmap.to_rgba(i + 3),\n",
    "    )[0]\n",
    "    dp_lines.append(l)\n",
    "    plt.xticks([2, 4, 8, 16, 32])\n",
    "    plt.yticks([5, 10, 15, 20])\n",
    "pp_lines = []\n",
    "pp_labels = []\n",
    "for i, num_microbatches in enumerate(pp_results):\n",
    "    pp_labels.append(f\"{num_microbatches} microbatches\")\n",
    "    l = axes[1].plot(\n",
    "        all_num_devices,\n",
    "        pp_results[num_microbatches],\n",
    "        marker=markers[i],\n",
    "        label=pp_labels[-1],\n",
    "        linestyle=styles[i],\n",
    "        c=pp_cmap.to_rgba(i + 3)\n",
    "    )[0]\n",
    "    pp_lines.append(l)\n",
    "axes[0].set_title(\"Data parallelism\")\n",
    "axes[1].set_title(\"Pipeline parallelism\")\n",
    "fig.text(0.5, -.025, '# Devices', ha='center', va='center')\n",
    "fig.text(-.01, 0.5, 'Speedup', va='center', ha='center', rotation='vertical')\n",
    "fig.tight_layout()\n",
    "dp_leg = axes[0].legend(dp_lines, dp_labels, loc='upper center', ncol=1)\n",
    "dp_leg.get_frame().set_linewidth(0.0)\n",
    "# Get the bounding box of the original legend.\n",
    "bb = dp_leg.get_bbox_to_anchor().transformed(axes[0].transAxes.inverted())\n",
    "\n",
    "# Change to location of the legend. \n",
    "xOffset = 0.75\n",
    "bb.x0 += xOffset\n",
    "bb.x1 += xOffset\n",
    "dp_leg.set_bbox_to_anchor(bb, transform = axes[0].transAxes)\n",
    "\n",
    "pp_leg = axes[1].legend(pp_lines, pp_labels, loc='upper center', ncol=1)\n",
    "pp_leg.get_frame().set_linewidth(0.0)\n",
    "# Get the bounding box of the original legend.\n",
    "bb = pp_leg.get_bbox_to_anchor().transformed(axes[1].transAxes.inverted())\n",
    "\n",
    "# Change to location of the legend. \n",
    "bb.x0 += xOffset\n",
    "bb.x1 += xOffset\n",
    "pp_leg.set_bbox_to_anchor(bb, transform = axes[1].transAxes)\n",
    "plt.savefig(\"dp_and_pp.pdf\", dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-wings",
   "metadata": {},
   "source": [
    "## Grid search simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns are: dp_degree / hp_degree / pp_degree / num_microbatches / throughput\n",
    "data = pd.read_csv(\n",
    "    \"euromlsys21_grid_search_results.csv\",\n",
    "    names=[\"D\", \"H\", \"P\", \"num_microbatches\", \"throughput\"],\n",
    "    header=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-stress",
   "metadata": {},
   "source": [
    "### Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 12\n",
    "data[\"speedup\"] = data[\"throughput\"] / 3725.917956\n",
    "only_D = [r[\"speedup\"] for i, r in data.iterrows() if r[\"H\"] == 1 and r[\"P\"] == 1]\n",
    "only_H = [r[\"speedup\"] for i, r in data.iterrows() if r[\"D\"] == 1 and r[\"P\"] == 1]\n",
    "half_DH = [r[\"speedup\"] for i, r in data.iterrows() if r[\"D\"] == r[\"H\"] and r[\"P\"] == 1]\n",
    "half_DH_devs = [\n",
    "    r[\"D\"] * r[\"H\"] * r[\"P\"]\n",
    "    for i, r in data.iterrows()\n",
    "    if r[\"D\"] == r[\"H\"] and r[\"P\"] == 1\n",
    "]\n",
    "# For each P degree, find the num_microbatches with best throughput (note it's not always 32!)\n",
    "pp_data = data[(data[\"D\"] == 1) & (data[\"H\"] == 1)]\n",
    "best_P = pp_data.loc[pp_data.groupby(\"P\")[\"throughput\"].idxmax()]\n",
    "\n",
    "devices = [2 ** i for i in range(5)]\n",
    "colors = []\n",
    "markers = [\"o\", \"D\", \"v\", \"s\", \"<\", \"x\"]\n",
    "styles = [\"-\", \"--\", \"-.\", \":\", (0, (3, 1, 1, 1, 1, 1))]\n",
    "c = np.arange(1, len(only_D) + 3)\n",
    "norm = mpl.colors.Normalize(vmin=c.min(), vmax=c.max())\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.Reds)\n",
    "cmap.set_array([])\n",
    "plt.figure(figsize=(4, 2))\n",
    "lines = []\n",
    "labels = [\n",
    "    \"Data parallelism\",\n",
    "    \"Horizontal parallelism\",\n",
    "    \"Pipeline parallelism\",\n",
    "    \"D+H parallelism\",\n",
    "]\n",
    "lines.append(\n",
    "    plt.plot(\n",
    "        devices,\n",
    "        only_D,\n",
    "        marker=markers[0],\n",
    "        linestyle=styles[0],\n",
    "        c=cmap.to_rgba(0 + 3),\n",
    "        label=labels[0],\n",
    "    )[0]\n",
    ")\n",
    "lines.append(\n",
    "    plt.plot(\n",
    "        devices,\n",
    "        only_H,\n",
    "        marker=markers[1],\n",
    "        linestyle=styles[1],\n",
    "        c=cmap.to_rgba(1 + 3),\n",
    "        label=labels[1],\n",
    "    )[0]\n",
    ")\n",
    "lines.append(\n",
    "    plt.plot(\n",
    "        best_P[\"P\"],\n",
    "        best_P[\"speedup\"],\n",
    "        marker=markers[2],\n",
    "        linestyle=styles[2],\n",
    "        c=cmap.to_rgba(2 + 3),\n",
    "        label=labels[2],\n",
    "    )[0]\n",
    ")\n",
    "lines.append(\n",
    "    plt.plot(\n",
    "        half_DH_devs,\n",
    "        half_DH,\n",
    "        marker=markers[3],\n",
    "        linestyle=styles[3],\n",
    "        c=cmap.to_rgba(3 + 3),\n",
    "        label=labels[3],\n",
    "    )[0]\n",
    ")\n",
    "plt.scatter(\n",
    "    data[\"D\"] * data[\"H\"] * data[\"P\"],\n",
    "    data[\"speedup\"],\n",
    "    marker=\"x\",\n",
    "    color=\"lightgray\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "# plt.grid(True)\n",
    "plt.yticks([5, 10, 15, 20])\n",
    "plt.xticks([2, 4, 8, 16])\n",
    "leg = plt.figlegend(lines, labels, loc=\"upper center\", ncol=2)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "# Get the bounding box of the original legend.\n",
    "bb = leg.get_bbox_to_anchor().transformed(plt.gca().transAxes.inverted())\n",
    "\n",
    "# Change to location of the legend.\n",
    "yOffset = 0.45\n",
    "bb.y0 += yOffset\n",
    "bb.y1 += yOffset\n",
    "leg.set_bbox_to_anchor(bb, transform=plt.gca().transAxes)\n",
    "plt.tight_layout()\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"# Devices\")\n",
    "plt.ylabel(\"Speedup\")\n",
    "plt.savefig(\"grid_search.pdf\", dpi=600, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
